<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>DOAI2019</title>
	<!-- <link rel="stylesheet" href="http://cdn.static.runoob.com/libs/bootstrap/3.3.7/css/bootstrap.min.css"> -->
	<link rel="stylesheet" href="bootstrap-3.3.7-dist/css/bootstrap.min.css">    	
	<link rel="stylesheet" type="text/css" href="css/mystyle.css"
	<script src="http://cdn.static.runoob.com/libs/jquery/2.1.1/jquery.min.js"></script>
	<!-- <script src="http://cdn.static.runoob.com/libs/bootstrap/3.3.7/js/bootstrap.min.js"></script> -->

	
	<style>
        body {
               background-color : rgb(250,250,250); /*UCLA bgcolor*/
        }
    </style>	
</head>

<body>

	<div class="container">

			<div class="jumbotron">
					<div class="content">
						<h1 style="text-align:center; margin-top:80px; font-weight: bold; color:rgb(100,10,250); font-size: 48px;">
							Detecting Objects in Aerial Images (DOAI)
						</h1>
			
						<!-- <p style="text-align:center; color:blue; position:relative; top:7%"> -->
						<p style="text-align:center; margin-top:15px; color: rgb(10,10,250); font-size: 32px;">
							<strong>
									<span style="font-style:italic">A Workshop at CVPR'2019</span>
							</strong> 
						</p>
						<!-- <body background="images/largeimage2.jpg"></body> -->
						<!-- <img src="images/largeimage2.jpg" class="img-responsive center-block" /> -->
					</div>				
						
				</div>

		<div class="row">
			<div class="span12">
			
				<div class="row">
					<div class="span4">
					</div>
					<div class="span4">
						<ul class="nav nav-tabs">
							<!-- <li class="active"> -->
							<li >
								<a href="index.html">Home</a>
							</li>
							<li>
								<a href="dataset.html">Dataset</a>
							</li>
							<li class="active">
							<!-- <li> -->
								<a href="tasks.html">Tasks</a>
							</li>
							<li>
								<a href="evaluation.html">Evaluation</a>
							</li>
							
							<li>
								<a href="results.html">Results</a>
							</li>
							<li>
								<a href="workshop.html">Workshop</a>
							</li>
							<li>
								<a href="contact.html">Contact</a>
							</li>
							
							<br />
							
						</ul>
					</div>
					<div class="span4">
					</div>
				</div>

				<h2>
					Overview
				</h2>
				<p>
					We propose three detection tasks. Task1 uses the initial annotation as ground truth.
					Task2 uses the generated axis-aligned bounding boxes as ground truth.
					The results from task2 are of great practical value. 
					We recommond you to test your algorithms by way of Task1. 
					You can use the provided train/val data to train and validate your detector. Validation data may also be used 
					for training when submitting results on the test set.
					External datas of any form is allowed. But must be reported during submission. Fine-tuning models that are pretrained
					on ImageNet or COCO are also allowed. 
				</p>

				<h2>
					<b>Task1</b> - Detection with horizontal bounding boxes
				</h2>
				<p>
					Detecting object with horizontal bounding boxes is usual in many previous contests for object
					detection. The aim of this task is to accurately localize the instance in terms of horizontal bounding
					box with (x, y, w, h) format. In the task, the ground truths for training and testing are generated
					by calculating the axis-aligned bounding boxes over original annotated bounding boxes.
				</p>
				<p>

				</p>

				<!-- <h3>
					Evaluation Server
				</h3>
				<p>
					For evaluation, you must registrate and submit on the
						<a href="http://www.icdar2017chinese.site:5080/evaluation1/">Evaluation Server</a>
				</p> -->

				<h3>
					Submission Format
				</h3>
				<p>
					You will be asked to submit a zip file containing results for all test images to evaluate your results.
					<!--The results are stored in 15 files, -->
					<!--<strong style="color:blue">"Task2_plane.txt, Task2_storage-tank.txt, ..."</strong>, each file contains all the results for a specific category.-->
					The format of the results is:
				</p>

				<pre>
					<code style="font-size:16px">
  x y w h category score
  x y w h category score
  ...
					</code>
				</pre>
				<!-- <a href="submissionformat/example_task2.rar">An example submission of task1</a> -->

				<h3>
					Evaluation Protocol
				</h3>
				<p>
					The evaluation protocol for horizontal bounding boxes follows the PASCAL VOC benchmark,
					which uses mean Average Precision(<strong>mAP</strong>) as the primary metric.
				</p>


				<h2>
					<b>Task2</b> - Detection with oriented bounding boxes<!--<strong>(Recommended)</strong> -->
				</h2>
					<p>
					The purpose of this task is to localize the ground object instances with an oriented bounding box.
					The oriented bounding box follows the same format with the original annotation {(x<sub>i</sub>, y<sub>i</sub>), i = 1,2,3,4}.
					</p>

				<!-- <h3>
					Evaluation Server
				</h3>
				<p>
					For evaluation, you must registrate and submit on the 
						<a href="http://www.icdar2017chinese.site:5080/evaluation1/">Evaluation Server</a>
				</p> -->

				<h3>
					Submission Format
				</h3>
				<p>
					You will be asked to submit a zip file containing results for all test images to evaluate your results. 
					<!-- The results are stored in 15 files, <strong style="color:blue">"Task1_plane.txt, Task1_storage-tank.txt, ..."</strong>, each file contains all the results for a specific category.   -->
					Each file is in the following format:
				</p>
				<pre>
					<code style="font-size:16px">
  x<sub>1</sub> y<sub>1</sub> x<sub>2</sub> y<sub>2</sub> x<sub>3</sub> y<sub>3</sub> x<sub>4</sub> y<sub>4</sub> category score 
  x<sub>1</sub> y<sub>1</sub> x<sub>2</sub> y<sub>2</sub> x<sub>3</sub> y<sub>3</sub> x<sub>4</sub> y<sub>4</sub> category score
  ...
					</code>
				</pre>

				<!-- <a href="submissionformat/example_task1.rar">An example submission of task2</a> -->

				<h3>
					Evaluation Protocol
				</h3>
				<p>
					The evaluation protocol for oriented bounding box is a little different from the protocol in the
					original PASCAL VOC. We use the intersection over the union area of two polygons(ground truth
					and prediction) to calculate the IoU. The rest follows the PASCAL VOC.
				</p>

				<h2>
					<b>Task3</b> - Jointly object detection and orientation estimation for movable instances
				</h2>
				<p>
					This task aims to estimate the orientation for movable instances(vehicles, planes, and ships), which is important when applied to tracking. 
					To make it clear, in this task, each instance's location and orientation is represented by (x, y, w, h, &theta;) 
					transferred from {(x<sub>i</sub>, y<sub>i</sub>), i = 1,2,3,4}. 
				</p>
				<p>
	
				</p>
	
				<!-- <h3>
					Evaluation Server
				</h3>
				<p>
					For evaluation, you must registrate and submit on the
						<a href="http://www.icdar2017chinese.site:5080/evaluation1/">Evaluation Server</a>
				</p> -->
	
				<h3>
					Submission Format
				</h3>
				<p>
					You will be asked to submit a zip file containing results for all test images to evaluate your results.
					<!--The results are stored in 15 files, -->
					<!--<strong style="color:blue">"Task2_plane.txt, Task2_storage-tank.txt, ..."</strong>, each file contains all the results for a specific category.-->
					The format of the results is: 
				</p>
	
				<pre>
					<code style="font-size:16px">
  x y w h &Theta; category score
  x y w h &Theta; category score
  ...
						</code>
					</pre>
					<!-- <a href="submissionformat/example_task2.rar">An example submission of task1</a> -->
	
				<h3>
					Evaluation Protocol
				</h3>
				<p>
					Note that the evaluation protocol of this task is slightly different from that of Task 2.
					In Task 2, if the IoU between the predicted box and ground truth is more than a certain threshold,
					it is assigned to be true positive(TP). 
					While in Task3, in addition to requiring IoU to be more than a threshold, the difference in angle is required to be less than a certain threshold. 
					As a result, the mAP for moveable classes in Task2 is upbound of Task3. 
					There is a similar metric in PASCAL3D+ which was called Average Viewpoint Precision(<strong>AVP</strong>).
				</p>

			</div>
		</div>
		<br>
<div align="center">
<a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3220030&c=9660403" alt="AmazingCounters.com"></a>
</div>
<br>		
	</div>

</body>
</html>



