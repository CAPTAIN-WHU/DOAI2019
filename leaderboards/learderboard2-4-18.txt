{
    "data": [
        {
            "BD": 0.866,
            "mAP": 0.795,
            "BC": 0.854,
            "HC": 0.761,
            "CC": 0.571,
            "TeamNames": "pca_lab",
            "LV": 0.794,
            "Harbor": 0.841,
            "Plane": 0.883,
            "RA": 0.774,
            "TC": 0.909,
            "TeamMembers": "Chengzheng Li, Chunyan Xu, Zhen Cui, Dan Wang, Tong Zhang, Jian Yang",
            "description": "Our method is FPN[1] based Faster R-CNN[2] and add rotate branch to RCNN head. We add semantic segmentation branch to RPN head, and utilize multi-stage FPN feature as well as semantic feature to enhance feature representation in RCNN head. Both in training and testing, we split the original images with 1024 and gap 512, and using DOTA_devkit to merge results when testing. We used multi-scale training&testing, and augmentations like flip and rotate when testing. We trained three models using ResNet101, ResneXt101 and ResNet101 mdcn version. The final result is ensemble version. [1] Lin T Y, Doll\u00e1r P, Girshick R B, et al. Feature Pyramid Networks for Object Detection[C]//CVPR. 2017, 1(2): 4. [2] Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems. 2015: 91-99.",
            "GTF": 0.798,
            "Institute": "Nanjing University of Science and Technology",
            "date": "2019-04-15 23:12:12",
            "Bridge": 0.657,
            "SP": 0.811,
            "SV": 0.746,
            "ST": 0.842,
            "SBF": 0.739,
            "created_date": "2019-04-15 23:12:12",
            "Ship": 0.881
        },
        {
            "BD": 0.856,
            "mAP": 0.792,
            "BC": 0.859,
            "HC": 0.765,
            "CC": 0.571,
            "TeamNames": "USTC-NELSLIP",
            "LV": 0.811,
            "Harbor": 0.817,
            "Plane": 0.893,
            "RA": 0.763,
            "TC": 0.908,
            "TeamMembers": "Yixing Zhu, Xueqing Wu, Jiaming Wang, Jun Du",
            "description": "sub_4_16_final_rec",
            "GTF": 0.809,
            "Institute": "University of Science and Technology of China",
            "date": "2019-04-15 23:33:51",
            "Bridge": 0.596,
            "SP": 0.818,
            "SV": 0.752,
            "ST": 0.857,
            "SBF": 0.695,
            "created_date": "2019-04-15 23:33:51",
            "Ship": 0.896
        },
        {
            "BD": 0.856,
            "mAP": 0.784,
            "BC": 0.857,
            "HC": 0.746,
            "CC": 0.44,
            "TeamNames": "AICyber",
            "LV": 0.815,
            "Harbor": 0.829,
            "Plane": 0.892,
            "RA": 0.763,
            "TC": 0.908,
            "TeamMembers": "Yang Xue; Yang Jirui; Wang Yashan; Zhang Yue; Sun Xian; Fu Kun",
            "description": "An improved version (v2) of R2CNN based on Faster-RCNN. \r\nReference code: https://github.com/DetectionTeamUCAS/R2CNN_Faster-RCNN_Tensorflow\r\nhttps://github.com/yangxue0827/R2CNN_FPN_Tensorflow",
            "GTF": 0.741,
            "Institute": "IECAS",
            "date": "2019-04-15 21:20:27",
            "Bridge": 0.644,
            "SP": 0.829,
            "SV": 0.774,
            "ST": 0.86,
            "SBF": 0.698,
            "created_date": "2019-04-15 21:20:27",
            "Ship": 0.896
        },
        {
            "BD": 0.839,
            "mAP": 0.764,
            "BC": 0.855,
            "HC": 0.698,
            "CC": 0.502,
            "TeamNames": "wonderwall",
            "LV": 0.749,
            "Harbor": 0.781,
            "Plane": 0.877,
            "RA": 0.74,
            "TC": 0.909,
            "TeamMembers": "Qi Dang, Shoupinp Shan, Xianmin Li",
            "description": "we use two ensembled models, faster rcnn and cascade rcnn, which are implemented by Detectron(https://github.com/facebookresearch/Detectron) and mmdetection(https://github.com/open-mmlab/mmdetection). The training skills we used mainly are data augmentation, multi scale training and inference, warmup, soft NMS.",
            "GTF": 0.776,
            "Institute": "Xidian University",
            "date": "2019-04-15 23:51:35",
            "Bridge": 0.547,
            "SP": 0.809,
            "SV": 0.743,
            "ST": 0.844,
            "SBF": 0.662,
            "created_date": "2019-04-15 23:51:35",
            "Ship": 0.89
        },
        {
            "BD": 0.85,
            "mAP": 0.762,
            "BC": 0.854,
            "HC": 0.741,
            "CC": 0.391,
            "TeamNames": "czh",
            "LV": 0.803,
            "Harbor": 0.811,
            "Plane": 0.88,
            "RA": 0.7,
            "TC": 0.908,
            "TeamMembers": "Zhonghan Chang",
            "description": "Our teamname is NIST-AITeam mebers are Kun Fu, Xian Sun, Zhonghan Chang, Yue Zhang, Zhuo Chen, Yingchao Feng, Tengfei Zhang and Peijin Wang. We come from School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences. And we also come from Key Laboratory of Network Information System Technology, Institute of Electronics, Chinese Academy of Sciences. Second_hbox",
            "GTF": 0.735,
            "Institute": "IECAS",
            "date": "2019-04-11 04:55:02",
            "Bridge": 0.644,
            "SP": 0.806,
            "SV": 0.727,
            "ST": 0.836,
            "SBF": 0.629,
            "created_date": "2019-04-11 04:55:02",
            "Ship": 0.884
        },
        {
            "BD": 0.839,
            "mAP": 0.749,
            "BC": 0.855,
            "HC": 0.649,
            "CC": 0.44,
            "TeamNames": "realman",
            "LV": 0.749,
            "Harbor": 0.778,
            "Plane": 0.877,
            "RA": 0.71,
            "TC": 0.903,
            "TeamMembers": "shoupin shan",
            "description": "faster rcnn",
            "GTF": 0.763,
            "Institute": "Xidian University",
            "date": "2019-04-14 10:40:19",
            "Bridge": 0.531,
            "SP": 0.765,
            "SV": 0.737,
            "ST": 0.839,
            "SBF": 0.662,
            "created_date": "2019-04-14 10:40:19",
            "Ship": 0.89
        },
        {
            "BD": 0.839,
            "mAP": 0.742,
            "BC": 0.842,
            "HC": 0.698,
            "CC": 0.502,
            "TeamNames": "chenting0618",
            "LV": 0.634,
            "Harbor": 0.774,
            "Plane": 0.809,
            "RA": 0.74,
            "TC": 0.906,
            "TeamMembers": "Ting Chen, Shaoxiong Li",
            "description": "cascade rcnn based on mmdetection, data augmentation, training and inference by multi scale",
            "GTF": 0.776,
            "Institute": "Northwestern Polytechnical University",
            "date": "2019-04-15 21:27:07",
            "Bridge": 0.547,
            "SP": 0.809,
            "SV": 0.741,
            "ST": 0.844,
            "SBF": 0.614,
            "created_date": "2019-04-15 21:27:07",
            "Ship": 0.796
        },
        {
            "BD": 0.819,
            "mAP": 0.737,
            "BC": 0.799,
            "HC": 0.698,
            "CC": 0.39,
            "TeamNames": "gwfemma",
            "LV": 0.779,
            "Harbor": 0.791,
            "Plane": 0.8,
            "RA": 0.717,
            "TC": 0.908,
            "TeamMembers": "guowei",
            "description": "MFPN++",
            "GTF": 0.703,
            "Institute": "Chongqing university",
            "date": "2019-04-15 07:58:42",
            "Bridge": 0.585,
            "SP": 0.786,
            "SV": 0.72,
            "ST": 0.809,
            "SBF": 0.609,
            "created_date": "2019-04-15 07:58:42",
            "Ship": 0.881
        },
        {
            "BD": 0.842,
            "mAP": 0.734,
            "BC": 0.816,
            "HC": 0.517,
            "CC": 0.34,
            "TeamNames": "Kakao Brain",
            "LV": 0.793,
            "Harbor": 0.827,
            "Plane": 0.801,
            "RA": 0.759,
            "TC": 0.908,
            "TeamMembers": "Jonghyuk Park, Jihoon Lee, Taegoo Kim, Ildoo Kim, Woonhyuk Baek, Sungbin Lim",
            "description": "Ensemble of below models with cross-validation\r\n1. Cascade Rcnn with resnet50 + Deformable Convolutional Layers.\r\n2. Faster Rcnn with resnext101\r\n3. cascade Rcnn with resnext101 + Deformable Convolutional Layers.\r\n(+ retinanet(resnext50) 1cv)\r\n4. SSD with resnet 101\r\n5. cascaded RCNN for one class detection model for container crane\r\n\r\nGSD Normalization : Estimate gsd with cnn and resize all test images into same gsd.",
            "GTF": 0.795,
            "Institute": "Kakao Brain",
            "date": "2019-04-15 23:50:09",
            "Bridge": 0.495,
            "SP": 0.774,
            "SV": 0.747,
            "ST": 0.834,
            "SBF": 0.617,
            "created_date": "2019-04-15 23:50:09",
            "Ship": 0.886
        },
        {
            "BD": 0.847,
            "mAP": 0.734,
            "BC": 0.835,
            "HC": 0.591,
            "CC": 0.43,
            "TeamNames": "peijin",
            "LV": 0.808,
            "Harbor": 0.777,
            "Plane": 0.81,
            "RA": 0.722,
            "TC": 0.909,
            "TeamMembers": "peijin",
            "description": "peijin wang",
            "GTF": 0.697,
            "Institute": "UCAS",
            "date": "2019-04-11 19:20:33",
            "Bridge": 0.607,
            "SP": 0.77,
            "SV": 0.675,
            "ST": 0.782,
            "SBF": 0.595,
            "created_date": "2019-04-11 19:20:33",
            "Ship": 0.892
        },
        {
            "BD": 0.83,
            "mAP": 0.731,
            "BC": 0.829,
            "HC": 0.611,
            "CC": 0.299,
            "TeamNames": "GoodLuck",
            "LV": 0.795,
            "Harbor": 0.834,
            "Plane": 0.884,
            "RA": 0.637,
            "TC": 0.907,
            "TeamMembers": "WangYingMing, WangDong, LuHuChuan",
            "description": "Our method is based on a two-stage framework.\r\nWe use the convlution layes of ResNet-50 as backbone.\r\nThe feature pyramid network (FPN) which is beneficial for scale variation of objects follows the backbone.\r\nThen the RPN network generates regions of interest (ROI), and RoI-align laye pools the features of RoI.\r\nFinally, the features of RoI feed into the head network to train with bounding box regression, category classification and mask segmentation tasks.\r\nAnd we develop a training and testing mechanism to deal with the large-size images. \r\nWe split the large size images into smaller pathches. \r\nWe also generate fake patches to train together and remove the influence of the divided objects.\r\nTo avoid the problems of predicting the angles of rotated bounding boxes, we predict the rotated bounding boxes by a segmentation task. \r\nThe result ensemble by multi-models and multi-scales.",
            "GTF": 0.724,
            "Institute": "Dalian University of Technology",
            "date": "2019-04-15 21:56:28",
            "Bridge": 0.604,
            "SP": 0.801,
            "SV": 0.694,
            "ST": 0.847,
            "SBF": 0.517,
            "created_date": "2019-04-15 21:56:28",
            "Ship": 0.888
        },
        {
            "BD": 0.819,
            "mAP": 0.731,
            "BC": 0.777,
            "HC": 0.682,
            "CC": 0.319,
            "TeamNames": "CVEO_WHU",
            "LV": 0.768,
            "Harbor": 0.814,
            "Plane": 0.809,
            "RA": 0.722,
            "TC": 0.909,
            "TeamMembers": "Chen Guanzhou, Zhu Kun, Tan Xiaoliang, Zhang Lifei, Liao Puyun",
            "description": "Our framework is based on DM-FPN(https://www.mdpi.com/2072-4292/11/7/755/htm)",
            "GTF": 0.765,
            "Institute": "Wuhan University",
            "date": "2019-04-07 19:40:25",
            "Bridge": 0.59,
            "SP": 0.747,
            "SV": 0.658,
            "ST": 0.779,
            "SBF": 0.651,
            "created_date": "2019-04-07 19:40:25",
            "Ship": 0.888
        },
        {
            "BD": 0.815,
            "mAP": 0.73,
            "BC": 0.799,
            "HC": 0.698,
            "CC": 0.362,
            "TeamNames": "ccy",
            "LV": 0.767,
            "Harbor": 0.788,
            "Plane": 0.799,
            "RA": 0.716,
            "TC": 0.907,
            "TeamMembers": "Chaoyue Chen,Wei Guo",
            "description": "Final1+",
            "GTF": 0.703,
            "Institute": "Chongqing university",
            "date": "2019-04-13 06:32:34",
            "Bridge": 0.578,
            "SP": 0.765,
            "SV": 0.702,
            "ST": 0.796,
            "SBF": 0.609,
            "created_date": "2019-04-13 06:32:34",
            "Ship": 0.88
        },
        {
            "BD": 0.841,
            "mAP": 0.727,
            "BC": 0.848,
            "HC": 0.705,
            "CC": 0.233,
            "TeamNames": "gzp",
            "LV": 0.741,
            "Harbor": 0.789,
            "Plane": 0.878,
            "RA": 0.694,
            "TC": 0.908,
            "TeamMembers": "gezhipeng",
            "description": "dense161",
            "GTF": 0.705,
            "Institute": "ucas",
            "date": "2019-04-15 21:10:33",
            "Bridge": 0.559,
            "SP": 0.784,
            "SV": 0.661,
            "ST": 0.828,
            "SBF": 0.575,
            "created_date": "2019-04-15 21:10:33",
            "Ship": 0.883
        },
        {
            "BD": 0.856,
            "mAP": 0.726,
            "BC": 0.857,
            "HC": 0.746,
            "CC": 0.438,
            "TeamNames": "CSULQQ",
            "LV": 0.813,
            "Harbor": 0.827,
            "Plane": 0.892,
            "RA": 0.763,
            "TC": 0.0,
            "TeamMembers": "Liu Qingqing",
            "description": "Task2_ensemble2",
            "GTF": 0.741,
            "Institute": "CSU",
            "date": "2019-04-13 23:04:25",
            "Bridge": 0.644,
            "SP": 0.829,
            "SV": 0.77,
            "ST": 0.854,
            "SBF": 0.687,
            "created_date": "2019-04-13 23:04:25",
            "Ship": 0.896
        },
        {
            "BD": 0.838,
            "mAP": 0.716,
            "BC": 0.841,
            "HC": 0.708,
            "CC": 0.364,
            "TeamNames": "bupt_det",
            "LV": 0.815,
            "Harbor": 0.829,
            "Plane": 0.886,
            "RA": 0.763,
            "TC": 0.0,
            "TeamMembers": "CaoXuemei",
            "description": "Res101D_fzC1C2_EsmP2-P4ErfConcat_800_MS_WarmUpCos_GlobalCtx_8conv_h_76w",
            "GTF": 0.723,
            "Institute": "bupt",
            "date": "2019-04-14 23:29:29",
            "Bridge": 0.636,
            "SP": 0.827,
            "SV": 0.774,
            "ST": 0.853,
            "SBF": 0.698,
            "created_date": "2019-04-14 23:29:29",
            "Ship": 0.896
        },
        {
            "BD": 0.832,
            "mAP": 0.711,
            "BC": 0.781,
            "HC": 0.588,
            "CC": 0.384,
            "TeamNames": "BESTORE",
            "LV": 0.756,
            "Harbor": 0.85,
            "Plane": 0.806,
            "RA": 0.713,
            "TC": 0.908,
            "TeamMembers": "zhuozheng",
            "description": "Our basic model is cascade RCNN[1] with dcn[2]-fpn[3]-ResNet[4]-101 as backbone.\r\nThe multi-scale training and test are used in this solution.\r\n\r\n[1]Cai Z, Vasconcelos N. Cascade r-cnn: Delving into high quality object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 6154-6162.\r\n[2]Dai J, Qi H, Xiong Y, et al. Deformable convolutional networks[C]//Proceedings of the IEEE international conference on computer vision. 2017: 764-773.\r\n[3]Lin T Y, Doll\u00e1r P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 2117-2125.\r\n[4]He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.",
            "GTF": 0.722,
            "Institute": "wuhan university",
            "date": "2019-04-13 02:39:32",
            "Bridge": 0.589,
            "SP": 0.767,
            "SV": 0.51,
            "ST": 0.773,
            "SBF": 0.509,
            "created_date": "2019-04-13 02:39:32",
            "Ship": 0.891
        },
        {
            "BD": 0.753,
            "mAP": 0.69,
            "BC": 0.729,
            "HC": 0.51,
            "CC": 0.196,
            "TeamNames": "twoam",
            "LV": 0.746,
            "Harbor": 0.773,
            "Plane": 0.804,
            "RA": 0.695,
            "TC": 0.905,
            "TeamMembers": "CaoXuemei",
            "description": "faster RCNN",
            "GTF": 0.615,
            "Institute": "bupt",
            "date": "2019-04-14 23:54:40",
            "Bridge": 0.511,
            "SP": 0.757,
            "SV": 0.743,
            "ST": 0.833,
            "SBF": 0.578,
            "created_date": "2019-04-14 23:54:40",
            "Ship": 0.886
        },
        {
            "BD": 0.812,
            "mAP": 0.675,
            "BC": 0.737,
            "HC": 0.551,
            "CC": 0.195,
            "TeamNames": "Inception",
            "LV": 0.707,
            "Harbor": 0.737,
            "Plane": 0.794,
            "RA": 0.719,
            "TC": 0.907,
            "TeamMembers": "Inception",
            "description": "RetinaNet",
            "GTF": 0.635,
            "Institute": "School of Articifical Intelligence",
            "date": "2019-04-15 19:47:35",
            "Bridge": 0.545,
            "SP": 0.755,
            "SV": 0.646,
            "ST": 0.743,
            "SBF": 0.458,
            "created_date": "2019-04-15 19:47:35",
            "Ship": 0.861
        },
        {
            "BD": 0.799,
            "mAP": 0.662,
            "BC": 0.82,
            "HC": 0.601,
            "CC": 0.27,
            "TeamNames": "gs_ai",
            "LV": 0.627,
            "Harbor": 0.751,
            "Plane": 0.806,
            "RA": 0.612,
            "TC": 0.908,
            "TeamMembers": "Yuwei Wang, Xixi Wang, Haiyang Wang, Tong Niu, Ensheng Wang",
            "description": "focus loss",
            "GTF": 0.585,
            "Institute": "Galaxy Space",
            "date": "2019-04-15 20:01:29",
            "Bridge": 0.56,
            "SP": 0.764,
            "SV": 0.603,
            "ST": 0.634,
            "SBF": 0.532,
            "created_date": "2019-04-15 20:01:29",
            "Ship": 0.719
        },
        {
            "BD": 0.799,
            "mAP": 0.658,
            "BC": 0.82,
            "HC": 0.596,
            "CC": 0.27,
            "TeamNames": "wes@yinhe.ht",
            "LV": 0.627,
            "Harbor": 0.729,
            "Plane": 0.806,
            "RA": 0.581,
            "TC": 0.908,
            "TeamMembers": "gaolegao",
            "description": "fun detection",
            "GTF": 0.58,
            "Institute": "\u4e2d\u79d1\u9662",
            "date": "2019-04-14 21:35:46",
            "Bridge": 0.56,
            "SP": 0.76,
            "SV": 0.603,
            "ST": 0.634,
            "SBF": 0.532,
            "created_date": "2019-04-14 21:35:46",
            "Ship": 0.719
        },
        {
            "BD": 0.792,
            "mAP": 0.653,
            "BC": 0.813,
            "HC": 0.601,
            "CC": 0.241,
            "TeamNames": "chaozhunya",
            "LV": 0.615,
            "Harbor": 0.751,
            "Plane": 0.805,
            "RA": 0.612,
            "TC": 0.908,
            "TeamMembers": "niutong",
            "description": "fpn detection",
            "GTF": 0.585,
            "Institute": "yhht",
            "date": "2019-04-14 19:48:32",
            "Bridge": 0.545,
            "SP": 0.764,
            "SV": 0.602,
            "ST": 0.595,
            "SBF": 0.502,
            "created_date": "2019-04-14 19:48:32",
            "Ship": 0.718
        },
        {
            "BD": 0.754,
            "mAP": 0.643,
            "BC": 0.746,
            "HC": 0.59,
            "CC": 0.138,
            "TeamNames": "VIPG",
            "LV": 0.621,
            "Harbor": 0.712,
            "Plane": 0.763,
            "RA": 0.727,
            "TC": 0.894,
            "TeamMembers": "Jinwang Wang",
            "description": "v104",
            "GTF": 0.599,
            "Institute": "Wuhan University",
            "date": "2019-04-13 03:12:48",
            "Bridge": 0.53,
            "SP": 0.753,
            "SV": 0.521,
            "ST": 0.675,
            "SBF": 0.472,
            "created_date": "2019-04-13 03:12:48",
            "Ship": 0.797
        },
        {
            "BD": 0.748,
            "mAP": 0.641,
            "BC": 0.747,
            "HC": 0.601,
            "CC": 0.108,
            "TeamNames": "jwwangchn",
            "LV": 0.63,
            "Harbor": 0.713,
            "Plane": 0.774,
            "RA": 0.729,
            "TC": 0.894,
            "TeamMembers": "Jinwang Wang",
            "description": "V104",
            "GTF": 0.603,
            "Institute": "Wuhan University",
            "date": "2019-04-13 00:22:21",
            "Bridge": 0.525,
            "SP": 0.743,
            "SV": 0.522,
            "ST": 0.665,
            "SBF": 0.457,
            "created_date": "2019-04-13 00:22:21",
            "Ship": 0.797
        },
        {
            "BD": 0.761,
            "mAP": 0.637,
            "BC": 0.745,
            "HC": 0.428,
            "CC": 0.145,
            "TeamNames": "XiangyuLiu",
            "LV": 0.605,
            "Harbor": 0.66,
            "Plane": 0.796,
            "RA": 0.639,
            "TC": 0.907,
            "TeamMembers": "Xiangyu Liu, Hong Pan",
            "description": "1",
            "GTF": 0.644,
            "Institute": "Southeast University",
            "date": "2019-04-14 09:19:57",
            "Bridge": 0.522,
            "SP": 0.729,
            "SV": 0.647,
            "ST": 0.711,
            "SBF": 0.47,
            "created_date": "2019-04-14 09:19:57",
            "Ship": 0.786
        },
        {
            "BD": 0.735,
            "mAP": 0.615,
            "BC": 0.701,
            "HC": 0.465,
            "CC": 0.177,
            "TeamNames": "Pengfei",
            "LV": 0.577,
            "Harbor": 0.736,
            "Plane": 0.692,
            "RA": 0.666,
            "TC": 0.884,
            "TeamMembers": "Pengfei",
            "description": "HIT_EIE",
            "GTF": 0.58,
            "Institute": "Harbin Institute of Technology",
            "date": "2019-04-14 05:26:53",
            "Bridge": 0.475,
            "SP": 0.676,
            "SV": 0.592,
            "ST": 0.681,
            "SBF": 0.421,
            "created_date": "2019-04-14 05:26:53",
            "Ship": 0.786
        },
        {
            "BD": 0.717,
            "mAP": 0.592,
            "BC": 0.764,
            "HC": 0.467,
            "CC": 0.256,
            "TeamNames": "Adamdad",
            "LV": 0.599,
            "Harbor": 0.631,
            "Plane": 0.786,
            "RA": 0.557,
            "TC": 0.905,
            "TeamMembers": "Xingyi Yang",
            "description": "We design a one-stage quadrilateral detector based on YOLOv3.In addition to the horizon bounding box regression, we stimulate the method of Textbox++ for predict the relative position of four vertexes to the HBB using logistic regression. The geometric constraint loss is also added to make sure our prediction results are more similar to standard markings. The focal loss and class-aware sampling is used for the severe sample imbalance in the DOTA annotation. In the training stage, rotation data-augmentation and multi-scale training is adapted to enhance the robustness of our model. The post-processing includes quadrilateral NMS and vertexes mapping. With multi-scale testing, we can give accurate detection result with 5fps for 1024*1024 input images. The backend is Resnet101-FPN,VGG-FPN and ResNeXt101-FPN trained on imagenet.",
            "GTF": 0.608,
            "Institute": "Southeast University",
            "date": "2019-04-09 19:44:35",
            "Bridge": 0.327,
            "SP": 0.627,
            "SV": 0.374,
            "ST": 0.628,
            "SBF": 0.453,
            "created_date": "2019-04-09 19:44:35",
            "Ship": 0.78
        },
        {
            "BD": 0.687,
            "mAP": 0.569,
            "BC": 0.764,
            "HC": 0.272,
            "CC": 0.263,
            "TeamNames": "caiest",
            "LV": 0.687,
            "Harbor": 0.644,
            "Plane": 0.786,
            "RA": 0.394,
            "TC": 0.904,
            "TeamMembers": "Hu yining, Yang Xingyi, Wang Hao, Zhu Yanqing, Zhu Hao, Xu Xiao, Wang Zheng",
            "description": "We design a one-stage quadrilateral detector based on YOLOv3.In addition to the horizon bounding box regression, we stimulate the method of Textbox++ for predict the relative position of four vertexes to the HBB using logistic regression. The geometric constraint loss is also added to make sure our prediction results are more similar to standard markings. The focal loss and class-aware sampling is used for the severe sample imbalance in the DOTA annotation. In the training stage, rotation data-augmentation and multi-scale training is adapted to enhance the robustness of our model. The post-processing includes quadrilateral NMS and vertexes mapping. With multi-scale testing, we can give accurate detection result with 5fps for 1024*1024 input images. The backend is Resnet101-FPN,VGG-FPN and ResNeXt101-FPN trained on imagenet.",
            "GTF": 0.49,
            "Institute": "School of Cyber Science and Enginnering, Southeast University",
            "date": "2019-04-15 11:09:59",
            "Bridge": 0.427,
            "SP": 0.617,
            "SV": 0.489,
            "ST": 0.603,
            "SBF": 0.378,
            "created_date": "2019-04-15 11:09:59",
            "Ship": 0.702
        },
        {
            "BD": 0.6,
            "mAP": 0.52,
            "BC": 0.64,
            "HC": 0.413,
            "CC": 0.19,
            "TeamNames": "zfpxs",
            "LV": 0.59,
            "Harbor": 0.544,
            "Plane": 0.603,
            "RA": 0.5,
            "TC": 0.761,
            "TeamMembers": "\u5468\u98de\u9e4f",
            "description": "faster_rcnn",
            "GTF": 0.485,
            "Institute": "none",
            "date": "2019-04-15 08:06:00",
            "Bridge": 0.4,
            "SP": 0.555,
            "SV": 0.506,
            "ST": 0.576,
            "SBF": 0.313,
            "created_date": "2019-04-15 08:06:00",
            "Ship": 0.637
        },
        {
            "BD": 0.485,
            "mAP": 0.479,
            "BC": 0.644,
            "HC": 0.204,
            "CC": 0.092,
            "TeamNames": "XD_Thriving",
            "LV": 0.489,
            "Harbor": 0.631,
            "Plane": 0.702,
            "RA": 0.596,
            "TC": 0.887,
            "TeamMembers": "Wenliang Sun, Peng Zhu, Tianyang Zhang, Jinyue Zhang, Shaona Wang",
            "description": "fcos",
            "GTF": 0.448,
            "Institute": "Xidian University",
            "date": "2019-04-15 06:24:20",
            "Bridge": 0.474,
            "SP": 0.025,
            "SV": 0.396,
            "ST": 0.631,
            "SBF": 0.302,
            "created_date": "2019-04-15 06:24:20",
            "Ship": 0.654
        },
        {
            "BD": 0.542,
            "mAP": 0.474,
            "BC": 0.578,
            "HC": 0.424,
            "CC": 0.123,
            "TeamNames": "huangqiuyu",
            "LV": 0.528,
            "Harbor": 0.51,
            "Plane": 0.585,
            "RA": 0.451,
            "TC": 0.683,
            "TeamMembers": "Qiuyu Huang, Feipeng Zhou",
            "description": "This is the first submission, using the most basic model of object detection. The network structure is the fater rcnn res101 fpn. The data is preprocessed according to the official script provided, then be entered into the fater rcnn res101 fpn neural network to train, and finally the test is performed. The difference between DOTA version 1.0 and version 1.5 is relatively large, so a minor adjustment is made here, but for the accuracy this adjustment is not significant.",
            "GTF": 0.411,
            "Institute": "Beihang university",
            "date": "2019-04-14 01:21:36",
            "Bridge": 0.352,
            "SP": 0.527,
            "SV": 0.45,
            "ST": 0.523,
            "SBF": 0.264,
            "created_date": "2019-04-14 01:21:36",
            "Ship": 0.63
        },
        {
            "BD": 0.684,
            "mAP": 0.473,
            "BC": 0.669,
            "HC": 0.196,
            "CC": 0.16,
            "TeamNames": "CangLing",
            "LV": 0.317,
            "Harbor": 0.436,
            "Plane": 0.63,
            "RA": 0.449,
            "TC": 0.904,
            "TeamMembers": "Kaixuan Lu, Luyang Zan, Yang xuan, Chen pan",
            "description": "SSD_Multi_Scale_Warmup_Fusion",
            "GTF": 0.544,
            "Institute": "Remote Sensing and Digital Earth, Chinese Academy of Sciences",
            "date": "2019-04-14 07:37:54",
            "Bridge": 0.22,
            "SP": 0.679,
            "SV": 0.224,
            "ST": 0.482,
            "SBF": 0.352,
            "created_date": "2019-04-14 07:37:54",
            "Ship": 0.616
        },
        {
            "BD": 0.477,
            "mAP": 0.456,
            "BC": 0.488,
            "HC": 0.26,
            "CC": 0.216,
            "TeamNames": "ADAMYXY",
            "LV": 0.572,
            "Harbor": 0.494,
            "Plane": 0.642,
            "RA": 0.349,
            "TC": 0.709,
            "TeamMembers": "Xingyi Yang",
            "description": "We design a one-stage quadrilateral detector based on YOLOv3.In addition to the horizon bounding box regression, we stimulate the method of Textbox++ for predict the relative position of four vertexes to the HBB using logistic regression. The geometric constraint loss is also added to make sure our prediction results are more similar to standard markings. The focal loss and class-aware sampling is used for the severe sample imbalance in the DOTA annotation. In the training stage, rotation data-augmentation and multi-scale training is adapted to enhance the robustness of our model. The post-processing includes quadrilateral NMS and vertexes mapping. With multi-scale testing, we can give accurate detection result with 5fps for 1024*1024 input images. The backend is Resnet101-FPN,VGG-FPN and ResNeXt101-FPN trained on imagenet.",
            "GTF": 0.325,
            "Institute": "Southeast University",
            "date": "2019-04-15 10:53:23",
            "Bridge": 0.389,
            "SP": 0.54,
            "SV": 0.439,
            "ST": 0.558,
            "SBF": 0.191,
            "created_date": "2019-04-15 10:53:23",
            "Ship": 0.647
        },
        {
            "BD": 0.504,
            "mAP": 0.443,
            "BC": 0.546,
            "HC": 0.263,
            "CC": 0.053,
            "TeamNames": "swl",
            "LV": 0.467,
            "Harbor": 0.534,
            "Plane": 0.51,
            "RA": 0.625,
            "TC": 0.711,
            "TeamMembers": "\u5b59\u6587\u4eae",
            "description": "The method we use is based on mask rcnn.We use the small image as input and adjust the size of the base anchor.The code is downloaded from https://github.com/facebookresearch/maskrcnn-benchmark. To detect objects in remote sensing images, we adopt some necessary tricks to improve it.",
            "GTF": 0.379,
            "Institute": "\u897f\u5b89\u7535\u5b50\u79d1\u6280\u5927\u5b66",
            "date": "2019-04-07 02:06:17",
            "Bridge": 0.452,
            "SP": 0.034,
            "SV": 0.466,
            "ST": 0.673,
            "SBF": 0.25,
            "created_date": "2019-04-07 02:06:17",
            "Ship": 0.618
        },
        {
            "BD": 0.091,
            "mAP": 0.126,
            "BC": 0.045,
            "HC": 0.0,
            "CC": 0.0,
            "TeamNames": "SerenaHe",
            "LV": 0.254,
            "Harbor": 0.014,
            "Plane": 0.218,
            "RA": 0.091,
            "TC": 0.036,
            "TeamMembers": "Shiyin He, Yuan Hua, Xuan Peng",
            "description": "this is a submission with result of an original mask-rcnn model. the train set and val set are splited into 800*800 with 200 overlap and they are transformed into a coco dataset format. There might be some empty files--baseball diamond,basketball court,container crane, roundabout and soccer ball field. these are replaced with result from the last try. The model is trained under pytorch. Data of horizontal bounding boxes is not used however, in this task, label in task1 is used as training data as the mask and horizontal bounding boxes are extracted from masks.The result was reached with 50 epoches and 1000 images per step. there are some question about ResultMerge because too many objects in some txt.Let\u2019s see how this network work.",
            "GTF": 0.0,
            "Institute": "Shanghai Jiao Tong University",
            "date": "2019-04-15 09:18:35",
            "Bridge": 0.115,
            "SP": 0.281,
            "SV": 0.232,
            "ST": 0.232,
            "SBF": 0.091,
            "created_date": "2019-04-15 09:18:35",
            "Ship": 0.313
        },
        {
            "BD": 0.0,
            "mAP": 0.033,
            "BC": 0.091,
            "HC": 0.091,
            "CC": 0.0,
            "TeamNames": "Adoreeeee",
            "LV": 0.0,
            "Harbor": 0.0,
            "Plane": 0.0,
            "RA": 0.0,
            "TC": 0.091,
            "TeamMembers": "Zhuo Wang, Zhan Su, Lingyun Wu, Haonan Qin, Jie Lei, Weiying Xie",
            "description": "The test results we submit are generated with our detection network which use a novel one - stage detection struction and achieve good results in remote sensing image detection. We took the first-order hourglass network as our backbone network, and added four detectors to the backbone network to detect objects of different scales, and superimposed the features of different scales on the channels, that is, features of different scales were fused. In addition, we also use the feature enhancement network to prevent the feature information of small objects from gradually disappearing with the increase of network depth. Our method effectively improves the accuracy of target detection, but the detection speed is still in the leading level.The results of this submission is based on the model we have trained for 15,000 epochs.",
            "GTF": 0.091,
            "Institute": "XiDian University",
            "date": "2019-04-01 05:35:52",
            "Bridge": 0.081,
            "SP": 0.0,
            "SV": 0.0,
            "ST": 0.0,
            "SBF": 0.0,
            "created_date": "2019-04-01 05:35:52",
            "Ship": 0.091
        }
    ]
}